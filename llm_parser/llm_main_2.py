#!/usr/bin/env python3
"""
LLM íŠ¸ë˜í”½ íŒŒì„œ - í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ì™€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ í†µí•© ì²˜ë¦¬

"""
import json
import sys
from pathlib import Path
from datetime import datetime
import threading
from mitmproxy import http
from typing import Optional, Dict, Any, List
import requests


project_root = Path(__file__).resolve().parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from llm_parser.common.utils import LLMAdapter 
from llm_parser.adapter.chat_gpt import ChatGPTAdapter
from llm_parser.adapter.claude import ClaudeAdapter
from llm_parser.adapter.gemini import GeminiAdapter
from llm_parser.adapter.deepseek import DeepSeekAdapter
from llm_parser.adapter.groq import GroqAdapter
from llm_parser.adapter.generic import GenericAdapter

from ocr.ocr_engine import OCREngine
from security import KeywordManager, ImageScanner, create_block_response



# ë¡œì»¬ ì„œë²„ ì„¤ì •
#LOCAL_SERVER_URL = "http://127.0.0.1:8080/logs"

# ë¡œì»¬ ì„œë²„ ì„¤ì •
LOCAL_SERVER_URL = "http://127.0.0.1:8080/control"

def get_control_decision(host: str, prompt: str) -> dict:
    """ì œì–´ ì„œë²„ì—ì„œ ë™ê¸°ì ìœ¼ë¡œ íŒë‹¨ ë°›ê¸° - ì‘ë‹µê¹Œì§€ ëŒ€ê¸°"""
    try:
        print(f"ğŸ”„ ì œì–´ ì„œë²„ì— ìš”ì²­ ì¤‘... ({host})")
        
        response = requests.post(
            LOCAL_SERVER_URL,
            json={
                'host': host,
                'prompt': prompt,
                'timestamp': datetime.now().isoformat()
            },
            timeout=2  # 2ì´ˆ íƒ€ì„ì•„ì›ƒ
        )
        
        if response.status_code == 200:
            decision = response.json()
            print(f"âœ… ì œì–´ ì„œë²„ ì‘ë‹µ: {decision}")
            return decision
        else:
            print(f"âŒ ì œì–´ ì„œë²„ ì˜¤ë¥˜: HTTP {response.status_code}")
            return {'action': 'allow'}
            
    except requests.exceptions.Timeout:
        print(f"â° ì œì–´ ì„œë²„ íƒ€ì„ì•„ì›ƒ - ê¸°ë³¸ í—ˆìš©")
        return {'action': 'allow'}
    except Exception as e:
        print(f"âŒ ì œì–´ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e} - ê¸°ë³¸ í—ˆìš©")
        return {'action': 'allow'}

# def send_to_local_server(data: dict):
#     """ë¡œì»¬ ì„œë²„ë¡œ ë°ì´í„° ì „ì†¡ (ë¹„ë™ê¸°)"""
#     def _send():
#         try:
#             response = requests.post(
#                 LOCAL_SERVER_URL,
#                 json=data,
#                 timeout=5,
#                 headers={'Content-Type': 'application/json'}
#             )
#             if response.status_code == 200:
#                 print(f"ë¡œê·¸ ì „ì†¡ ì„±ê³µ: {len(str(data))} bytes")
#             else:
#                 print(f"ë¡œê·¸ ì „ì†¡ ì‹¤íŒ¨: HTTP {response.status_code}")
#         except Exception as e:
#             print(f"ë¡œì»¬ ì„œë²„ ì „ì†¡ ì—ëŸ¬: {str(e)}")
    
#     # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰ (mitmproxy ë¸”ë¡œí‚¹ ë°©ì§€)
#     thread = threading.Thread(target=_send, daemon=True)
#     thread.start()

# -------------------------------
# í†µí•© LLM Logger
# -------------------------------
class UnifiedLLMLogger:
    def __init__(self):
        # íŒŒì¼/í´ë” ì¤€ë¹„
        self.base_dir = Path.home() / ".llm_proxy"
        self.json_log_file = self.base_dir / "llm_requests.json"
        self.download_dir = self.base_dir / "downloads"
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.download_dir.mkdir(parents=True, exist_ok=True)

        # # í›„ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë” ê²½ë¡œ ì •ì˜
        # self.processed_dir = self.base_dir / "processed"
        # self.failed_dir = self.base_dir / "failed"
        # # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        # self.processed_dir.mkdir(exist_ok=True)
        # self.failed_dir.mkdir(exist_ok=True)


        # ocr ì—”ì§„ ì´ˆê¸°í™” ë° í‚¤ì›Œë“œ ì°¨ë‹¨ db ë§¤ë‹ˆì € ì´ˆê¸°í™”
        # self.keyword_manager = KeywordManager()
        # self.image_scanner = ImageScanner()
        # self.ocr_engine = OCREngine(['ko', 'en'])


        # LLM ê´€ë ¨ í˜¸ìŠ¤íŠ¸ ì§‘í•© (ë¶€ë¶„ ë¬¸ìì—´ ë§¤ì¹­ì— ì‚¬ìš©)
        self.LLM_HOSTS = {
            "chatgpt.com", "claude.ai", "gemini.google.com", 
            "chat.deepseek.com", "groq.com",
            "generativelanguage.googleapis.com", "aiplatform.googleapis.com",
            
        }

        # adapters ë§¤í•‘ì€ ëŸ°íƒ€ì„ì— ì„í¬íŠ¸í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤í™” (ìˆœí™˜ import ë°©ì§€)
        self.adapters: Dict[str, LLMAdapter] = {}
        self.default_adapter = None
        self._init_adapters()

    def _init_adapters(self):

        def inst(cls):
                # í´ë˜ìŠ¤ê°€ Noneì´ ì•„ë‹ˆë©´ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±, ì•„ë‹ˆë©´ None ë°˜í™˜
                return cls() if cls else None

        self.adapters["chatgpt.com"] = inst(ChatGPTAdapter)
        self.adapters["claude.ai"] = inst(ClaudeAdapter)
        self.adapters["gemini.google.com"] = inst(GeminiAdapter)
        self.adapters["chat.deepseek.com"] = inst(DeepSeekAdapter)
        self.adapters["groq.com"] = inst(GroqAdapter)

        self.adapters["api.openai.com"] = inst(GenericAdapter)
        self.adapters["api.anthropic.com"] = inst(ClaudeAdapter)
        self.adapters["generativelanguage.googleapis.com"] = inst(GeminiAdapter)
        self.adapters["aiplatform.googleapis.com"] = inst(GeminiAdapter)

        # GenericAdapterê°€ ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ, ì—†ìœ¼ë©´ ë¹ˆ ê¸°ë³¸ ì–´ëŒ‘í„° ì‚¬ìš©
        self.default_adapter = inst(GenericAdapter) or LLMAdapter()



    def is_llm_request(self, flow: http.HTTPFlow) -> bool:
        return any(host in flow.request.pretty_host for host in self.LLM_HOSTS)

    def get_adapter(self, host: str) -> LLMAdapter:
        for adapter_host, adapter in self.adapters.items():
            if adapter is None:
                continue
            if adapter_host in host:
                return adapter
        return self.default_adapter

    def safe_decode_content(self, content: bytes) -> str:
        if not content:
            return ""
        try:
            return content.decode('utf-8', errors='replace')
        except Exception:
            return f"[BINARY_CONTENT: {len(content)} bytes]"

    def parse_json_safely(self, content: str) -> dict:
        try:
            return json.loads(content)
        except json.JSONDecodeError:
            return {}


    # ë¡œê·¸ ì €ì¥ ë¡œì§ 
    def save_log(self, log_entry: Dict[str, Any]):
        try:
            logs = []
            if self.json_log_file.exists():
                try:
                    content = self.json_log_file.read_text(encoding="utf-8").strip()
                    if content:
                        logs = json.loads(content)
                except (json.JSONDecodeError, OSError):
                    logs = [] # íŒŒì¼ì´ ì†ìƒë˜ì—ˆìœ¼ë©´ ìƒˆë¡œ ì‹œì‘
            
            logs.append(log_entry)
            
            # ìµœê·¼ 100ê°œ ë¡œê·¸ë§Œ ìœ ì§€
            if len(logs) > 100:
                logs = logs[-100:]

            self.json_log_file.write_text(json.dumps(logs, indent=2, ensure_ascii=False), encoding='utf-8')
        except Exception as e:
            print(f"[ERROR] ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")



    # mitmproxy hook: ìš”ì²­(Request) ì²˜ë¦¬ (ë™ê¸° í˜¸ì¶œ)
    def request(self, flow: http.HTTPFlow):
        try:
            if not self.is_llm_request(flow) or flow.request.method != 'POST':
                return
            host = flow.request.pretty_host
  
            request_data = None
            content_type = flow.request.headers.get("content-type", "").lower()

            # 1. Content-Typeì— ë”°ë¼ íŒŒì‹± ë°©ì‹ì„ ê²°ì •í•©ë‹ˆë‹¤.
            if "application/x-www-form-urlencoded" in content_type:
                # Gemini ì›¹ íŠ¸ë˜í”½ê³¼ ê°™ì€ Form ë°ì´í„°ëŠ” urlencoded_formìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
                request_data = flow.request.urlencoded_form
            elif "application/json" in content_type:
                # ChatGPT, Claude APIì™€ ê°™ì€ ì¼ë°˜ì ì¸ ê²½ìš°ëŠ” JSONìœ¼ë¡œ íŒŒì‹±í•©ë‹ˆë‹¤.
                request_body = self.safe_decode_content(flow.request.content)
                request_data = self.parse_json_safely(request_body)

            # íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë” ì´ìƒ ì§„í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
            if not request_data:
                return

            adapter = self.get_adapter(host)
            # adapterê°€ Noneì´ë©´ ê±´ë„ˆë›°ê¸°
            if not adapter:
                return
            prompt = None
            attachments = []
            try:
                prompt = adapter.extract_prompt(request_data, host)
            except Exception as e:
                print(f"[WARN] adapter.extract_* í˜¸ì¶œ ì¤‘ ì˜ˆì™¸: {e}")



            # ë™ê¸°ì ìœ¼ë¡œ ì œì–´ ì„œë²„ ì‘ë‹µ ëŒ€ê¸°
                print("â³ ì œì–´ ì„œë²„ ì‘ë‹µ ëŒ€ê¸° ì¤‘...")
                control_decision = get_control_decision(host, prompt)
                action = control_decision.get('action', 'allow')
                
                print(f"ìµœì¢… ê²°ì •: {action}")
                
                # ì•¡ì…˜ ì²˜ë¦¬
                if action == 'block':
                    print("ìš”ì²­ ì°¨ë‹¨!")
                    flow.response = http.Response.make(
                        403,
                        b"Request blocked by security policy",
                        {"Content-Type": "text/plain"}
                    )
                elif action == 'modify':
                    modified_prompt = control_decision.get('modified_prompt', '[MODIFIED]')
                    print(f"í”„ë¡¬í”„íŠ¸ ë³€ì¡°: {modified_prompt[:50]}...")
                    # TODO: ì‹¤ì œ ë³€ì¡° ë¡œì§ì€ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ
                else:
                    print("ìš”ì²­ í—ˆìš©")




            if prompt or attachments:
                log_entry = {
                    "time": datetime.now().isoformat(),
                    "host": host,
                    "prompt": prompt or "",
                    "interface": "llm"
                }
                self.save_log(log_entry)
                print(f"[LOG] {host} - {(prompt[:80] if prompt else '[ì²¨ë¶€íŒŒì¼]')}...")
        except Exception as e:
            print(f"[ERROR] request hook ì‹¤íŒ¨: {e}")



    # # mitmproxy hook: ì‘ë‹µ(Response) ì²˜ë¦¬
    # async def response(self, flow: http.HTTPFlow):
    #     """
    #     mitmproxyì˜ ë¹„ë™ê¸° ì´ë²¤íŠ¸ í›…ì…ë‹ˆë‹¤.
    #     íŒŒì¼ ë‹¤ìš´ë¡œë“œ ìš”ì²­ì„ ê°ì§€í•˜ê³  ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë‹¤ìš´ë¡œë“œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    #     """

    #     adapter = self.get_adapter(flow.request.pretty_host)
    #     if not adapter:
    #         return

    #     # 2. ì–´ëŒ‘í„°ê°€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ìš”ì²­ì´ë¼ê³  íŒë‹¨í•˜ëŠ” ê²½ìš°ì—ë§Œ ë¡œì§ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    #     if not adapter.is_file_download_request(flow):
    #         return

    #     try:
    #         file_info = adapter.extract_file_info(flow)
    #         if not file_info:
    #             return

    #         cert_path = self.base_dir / ".mitmproxy" / "mitmproxy-ca-cert.pem"
    #         if not cert_path.exists():
    #             print(f"[ERROR] mitmproxy CA ì¸ì¦ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {cert_path}")
    #             return

    #         print(f"[INFO] íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {file_info.get('file_name', 'unknown')}")

    #         # 3. awaitë¥¼ ì‚¬ìš©í•˜ì—¬ download_file ì½”ë£¨í‹´ì„ ì§ì ‘ ì‹¤í–‰í•©ë‹ˆë‹¤.
    #         from ocr.downloader import download_file 
    #         result = await download_file(file_info, self.download_dir, cert_path)

    #         # 4. ë‹¤ìš´ë¡œë“œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ê³  ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤.
    #         if result:
    #             print(f"[SUCCESS] íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {result}")
    #             # ì—¬ê¸°ì— OCR ë“± í›„ì† ì‘ì—…ì„ ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    #         else:
    #             print(f"[FAILURE] íŒŒì¼ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì´ì „ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    #     except Exception as e:
    #         import traceback
    #         print(f"[ERROR] response hook ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}\n{traceback.format_exc()}")
        
# mitmproxy ì• ë“œì˜¨ ë“±ë¡ 
addons = [UnifiedLLMLogger()]
